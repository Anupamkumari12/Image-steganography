{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8462577,"sourceType":"datasetVersion","datasetId":5043999},{"sourceId":8617186,"sourceType":"datasetVersion","datasetId":5043052}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***DCT & Inverted LSB based Steganography***","metadata":{}},{"cell_type":"markdown","source":"# **ZigZag Traversing**","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\n\n# Zigzag scan of a matrix\n# Argument is a two-dimensional matrix of any size,\n# not strictly a square one.\n# Function returns a 1-by-(m*n) array,\n# where m and n are sizes of an input matrix,\n# consisting of its items scanned by a zigzag method.\n\ndef zigzag(input):\n\n    h = 0\n    v = 0\n\n    vmin = 0\n    hmin = 0\n\n    vmax = input.shape[0]\n    hmax = input.shape[1]\n\n    #print(vmax ,hmax )\n\n    i = 0\n\n    output = np.zeros(( vmax * hmax))\n\n    while ((v < vmax) and (h < hmax)):\n\n        if ((h + v) % 2) == 0:                 # going up\n\n            if (v == vmin):\n                #print(1)\n                output[i] = input[v, h]        # if we got to the first line\n\n                if (h == hmax):\n                    v = v + 1\n                else:\n                    h = h + 1\n\n                i = i + 1\n\n            elif ((h == hmax -1 ) and (v < vmax)):   # if we got to the last column\n                #print(2)\n                output[i] = input[v, h]\n                v = v + 1\n                i = i + 1\n\n            elif ((v > vmin) and (h < hmax -1 )):    # all other cases\n                #print(3)\n                output[i] = input[v, h]\n                v = v - 1\n                h = h + 1\n                i = i + 1\n\n\n        else:                                    # going down\n\n            if ((v == vmax -1) and (h <= hmax -1)):       # if we got to the last line\n                #print(4)\n                output[i] = input[v, h]\n                h = h + 1\n                i = i + 1\n\n            elif (h == hmin):                  # if we got to the first column\n                #print(5)\n                output[i] = input[v, h]\n\n                if (v == vmax -1):\n                    h = h + 1\n                else:\n                    v = v + 1\n\n                i = i + 1\n\n            elif ((v < vmax -1) and (h > hmin)):     # all other cases\n                #print(6)\n                output[i] = input[v, h]\n                v = v + 1\n                h = h - 1\n                i = i + 1\n\n\n\n\n        if ((v == vmax-1) and (h == hmax-1)):          # bottom right element\n            #print(7)\n            output[i] = input[v, h]\n            break\n\n    #print ('v:',v,', h:',h,', i:',i)\n    return output\n\n\n\n\n# Inverse zigzag scan of a matrix\n# Arguments are: a 1-by-m*n array,\n# where m & n are vertical & horizontal sizes of an output matrix.\n# Function returns a two-dimensional matrix of defined sizes,\n# consisting of input array items gathered by a zigzag method.\n\n\ndef inverse_zigzag(input, vmax, hmax):\n\n    #print input.shape\n\n    # initializing the variables\n    h = 0\n    v = 0\n\n    vmin = 0\n    hmin = 0\n\n    output = np.zeros((vmax, hmax))\n\n    i = 0\n\n    while ((v < vmax) and (h < hmax)):\n        #print ('v:',v,', h:',h,', i:',i)\n        if ((h + v) % 2) == 0:                 # going up\n\n            if (v == vmin):\n                #print(1)\n\n                output[v, h] = input[i]        # if we got to the first line\n\n                if (h == hmax):\n                    v = v + 1\n                else:\n                    h = h + 1\n\n                i = i + 1\n\n            elif ((h == hmax -1 ) and (v < vmax)):   # if we got to the last column\n                #print(2)\n                output[v, h] = input[i]\n                v = v + 1\n                i = i + 1\n\n            elif ((v > vmin) and (h < hmax -1 )):    # all other cases\n                #print(3)\n                output[v, h] = input[i]\n                v = v - 1\n                h = h + 1\n                i = i + 1\n\n\n        else:                                    # going down\n\n            if ((v == vmax -1) and (h <= hmax -1)):       # if we got to the last line\n                #print(4)\n                output[v, h] = input[i]\n                h = h + 1\n                i = i + 1\n\n            elif (h == hmin):                  # if we got to the first column\n                #print(5)\n                output[v, h] = input[i]\n                if (v == vmax -1):\n                    h = h + 1\n                else:\n                    v = v + 1\n                i = i + 1\n\n            elif((v < vmax -1) and (h > hmin)):     # all other cases\n                output[v, h] = input[i]\n                v = v + 1\n                h = h - 1\n                i = i + 1\n\n\n\n\n        if ((v == vmax-1) and (h == hmax-1)):          # bottom right element\n            #print(7)\n            output[v, h] = input[i]\n            break\n\n\n    return output\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Image Processing**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Numpy Macros\nHORIZ_AXIS = 1\nVERT_AXIS  = 0\n\n# Standard quantization table as defined by JPEG\nJPEG_STD_LUM_QUANT_TABLE = np.asarray([\n                                        [16, 11, 10, 16,  24, 40,   51,  61],\n                                        [12, 12, 14, 19,  26, 58,   60,  55],\n                                        [14, 13, 16, 24,  40, 57,   69,  56],\n                                        [14, 17, 22, 29,  51, 87,   80,  62],\n                                        [18, 22, 37, 56,  68, 109, 103,  77],\n                                        [24, 36, 55, 64,  81, 104, 113,  92],\n                                        [49, 64, 78, 87, 103, 121, 120, 101],\n                                        [72, 92, 95, 98, 112, 100, 103,  99]\n                                      ],\n                                      dtype = np.float32)\n# Image container class\nclass YCC_Image(object):\n    def __init__(self, cover_image):\n        self.height, self.width = cover_image.shape[:2]\n        self.channels = [\n                         split_image_into_8x8_blocks(cover_image[:,:,0]),\n                         split_image_into_8x8_blocks(cover_image[:,:,1]),\n                         split_image_into_8x8_blocks(cover_image[:,:,2]),\n                        ]\n\n\ndef stitch_8x8_blocks_back_together(Nc, block_segments):\n    '''\n    Take the array of 8x8 pixel blocks and put them together by row so the numpy.block() method can sitch it back together\n    '''\n    image_rows = []\n    temp = []\n    for i in range(len(block_segments)):\n        if i > 0 and not(i % int(Nc / 8)):\n            image_rows.append(temp)\n            temp = [block_segments[i]]\n        else:\n            temp.append(block_segments[i])\n    image_rows.append(temp)\n\n    return np.block(image_rows)\n\n\ndef split_image_into_8x8_blocks(image):\n    blocks = []\n    for vert_slice in np.vsplit(image, int(image.shape[0] / 8)):\n        for horiz_slice in np.hsplit(vert_slice, int(image.shape[1] / 8)):\n            blocks.append(horiz_slice)\n    return blocks\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **File processing**","metadata":{}},{"cell_type":"code","source":"import os\n\ndef get_file_paths(directory):\n    file_paths = []\n    \n    # Traverse the directory and collect file paths\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            file_paths.append(file_path)\n    return file_paths\n\ndef rename_file(file_path, new_directory):\n    file_base, file_ext = os.path.splitext(file_path)\n    file_direc, file_name = os.path.split(file_base)\n    \n    # Construct the new file name\n    new_file_name = f\"{new_directory}{file_name}{'_steg'}{file_ext}\"\n    return new_file_name\n\ndef read_text_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:  # Open in read mode with UTF-8 encoding\n        file_content = file.read()  # Read the entire file\n    return file_content\n\ndef stego_filename(file_path):\n    file_base, file_ext = os.path.splitext(file_path)\n    file_direc, file_name = os.path.split(file_base)\n    return file_name\n\ndef cover_filename(file_path, new_directory):\n    file_base, file_ext = os.path.splitext(file_path)\n    file_direc, file_name = os.path.split(file_base)\n    file_name = file_name.replace('_steg', '')\n    new_file_name = f\"{new_directory}{file_name}{file_ext}\"\n    return new_file_name\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Security Encryption**","metadata":{}},{"cell_type":"code","source":"import base64\n\ndef generate_key(password):\n    \n    # Generate a key based on the password\n    password_padded = password.ljust(32, b'\\0')[:32]  # Pad or trim to 32 bytes\n    #print(\"Padded pass: \", password_padded,\"\\nLength: \", len(password_padded),\"\\n\")\n    key = base64.urlsafe_b64encode(password_padded)\n    #print(\"Encrypted key: \", key,\"\\nKey Length: \", len(key))\n    return key\n\ndef encrypt_message(message, key):\n        return key+message\n\ndef decrypt_message(encrypted_message, key):\n        #print(\"\\nEntered key: \", key)\n        #print(\"\\n\",encrypted_message)\n        if key == encrypted_message[:len(key)]:\n            return encrypted_message[len(key):]\n        else:\n            raise ValueError(\"Wrong decryption key entered!\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Embedding**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport struct\nimport bitstring\nimport numpy  as np\nimport time\n\n#import zigzag as zz\n#import image_processing as img\n\nstart_time = time.time()\n\n\ndef _embed_bits_into_dct(encoded_bits, dct_blocks):\n    \"\"\" \n    Embeds encoded bits into quantized DCT coefficients.\n\n    Args:\n        encoded_bits (bitstring.BitArray): The bits to embed.\n        dct_blocks (list): List of quantized DCT blocks.\n\n    Returns:\n        list: List of modified DCT blocks with embedded bits.\n    \"\"\"\n    data_complete = False\n    encoded_bits.pos = 0\n    encoded_data_len = bitstring.pack('uint:32', len(encoded_bits))\n    converted_blocks = []\n    \n    for current_dct_block in dct_blocks:\n        for i in range(1, len(current_dct_block)):\n            curr_coeff = np.int32(current_dct_block[i])\n            if (curr_coeff > 1):\n                curr_coeff = np.uint8(current_dct_block[i])\n                \n                if (encoded_bits.pos == (len(encoded_bits) - 1)): \n                    data_complete = True\n                    break\n                    \n                    \n                # Read bits separately to avoid BitStream subtraction\n                if encoded_data_len.pos < len(encoded_data_len):\n                    embed_bit = encoded_data_len.read(1).uint \n                else:\n                    embed_bit = encoded_bits.read(1).uint\n\n                # --- INVERTED LSB INSERTION ---\n                embed_bit = 1 - embed_bit  # Invert the bit\n                curr_coeff &= ~0x01         # Clear the LSB\n                curr_coeff |= embed_bit     # Embed the inverted bit\n\n                current_dct_block[i] = np.float32(curr_coeff)\n        converted_blocks.append(current_dct_block)\n\n    if not(data_complete): \n        raise ValueError(\"Data didn't fully embed into cover image!\")\n\n    return converted_blocks\n\n\ndef stego_execute(file_path, new_directory, key):\n    start_time1 = time.time()\n    print(\"\\nProcessing \", file_path)\n    try:\n        NUM_CHANNELS = 3\n        COVER_IMAGE_FILEPATH  = file_path \n        SECRET_MESSAGE_PATH = \"/kaggle/input/secretmsg/secret_msg.txt\"\n        STEGO_IMAGE_FILEPATH  = rename_file(file_path, new_directory)\n        SECRET_MESSAGE = read_text_file(SECRET_MESSAGE_PATH)\n\n        gen_key = generate_key(key)\n\n\n        raw_cover_image = cv2.imread(COVER_IMAGE_FILEPATH, flags=cv2.IMREAD_COLOR)\n        height, width   = raw_cover_image.shape[:2]\n        \n        # Force Image Dimensions to be 8x8 compliant\n        while(height % 8): height += 1 # Rows\n        while(width  % 8): width  += 1 # Cols\n        valid_dim = (width, height)\n        padded_image    = cv2.resize(raw_cover_image, valid_dim)\n        cover_image_f32 = np.float32(padded_image)\n        cover_image_YCC = YCC_Image(cv2.cvtColor(cover_image_f32, cv2.COLOR_BGR2YCrCb))\n\n        # Placeholder for holding stego image data\n        stego_image = np.empty_like(cover_image_f32)\n\n        for chan_index in range(NUM_CHANNELS):\n            # FORWARD DCT STAGE\n            dct_blocks = [cv2.dct(block) for block in cover_image_YCC.channels[chan_index]]\n\n            # QUANTIZATION STAGE\n            dct_quants = [np.around(np.divide(item, JPEG_STD_LUM_QUANT_TABLE)) for item in dct_blocks]\n\n            # Sort DCT coefficients by frequency\n            sorted_coefficients = [zigzag(block) for block in dct_quants]\n\n            # Embed data in Luminance layer\n            if (chan_index == 0):\n                # DATA INSERTION STAGE\n                secret_data = \"\"\n                for char in SECRET_MESSAGE.encode('ascii'): secret_data += bitstring.pack('uint:8', char)\n                secret_data = encrypt_message(secret_data, gen_key)\n                embedded_dct_blocks   = _embed_bits_into_dct(secret_data, sorted_coefficients)\n                desorted_coefficients = [inverse_zigzag(block, vmax=8,hmax=8) for block in embedded_dct_blocks]\n            else:\n                # Reorder coefficients to how they originally were\n                desorted_coefficients = [inverse_zigzag(block, vmax=8,hmax=8) for block in sorted_coefficients]\n\n            # DEQUANTIZATION STAGE\n            dct_dequants = [np.multiply(data, JPEG_STD_LUM_QUANT_TABLE) for data in desorted_coefficients]\n\n            # Inverse DCT Stage\n            idct_blocks = [cv2.idct(block) for block in dct_dequants]\n\n            # Rebuild full image channel\n            stego_image[:,:,chan_index] = np.asarray(stitch_8x8_blocks_back_together(cover_image_YCC.width, idct_blocks))\n\n\n        # Convert back to RGB (BGR) Colorspace\n        stego_image_BGR = cv2.cvtColor(stego_image, cv2.COLOR_YCR_CB2BGR)\n\n        # Clamp Pixel Values to [0 - 255]\n        final_stego_image = np.uint8(np.clip(stego_image_BGR, 0, 255))\n\n        # Write stego image\n        cv2.imwrite(STEGO_IMAGE_FILEPATH, final_stego_image)\n        print(file_path,\" embedding done.\")\n    \n    except FileNotFoundError as e:\n        print(f\"Error: File not found - {e}\")\n    except cv2.error as e:\n        print(f\"Error: OpenCV error - {e}\")\n    except ValueError as e:\n        print(f\"Error: Data embedding failed - {e}\")\n    except Exception as e:  # Catch any other unexpected exceptions\n        print(f\"Error: An unexpected error occurred - {e}\")\n        \n    end_time1 = time.time()\n\n    # Calculate the elapsed time\n    elapsed_time1 = end_time1 - start_time1\n\n    # Print the time\n    print(f\"Time taken: {elapsed_time1:.2f} seconds\\n\")\n\ndirectory = '/kaggle/input/test-dct'  # Input data directory\nnew_directory = '/kaggle/working/'    # Output data directory\n\n# Get the list of file paths\nfile_paths = get_file_paths(directory)\n\nkey = input(\"Enter encryption key: \").encode()\n\n# Print the file paths (optional)\nfor file_path in file_paths:\n    stego_execute(file_path, new_directory, key)\n\nprint(\"Data embedding successful!\")\nend_time = time.time()\n\n# Calculate the elapsed time\nelapsed_time = end_time - start_time\n\n# Print the result\nprint(f\"Total time taken for execution: {elapsed_time:.2f} seconds\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Extraction**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport struct\nimport bitstring\nimport numpy  as np\n\n#import zigzag as zz\n#import image_processing as img\n#import dct_embedding as src\n\nstart_time = time.time()\n\ndef _extract_bits_from_dct(dct_blocks):\n    \n    \"\"\"\n    Extracts encoded bits from quantized DCT coefficients.\n\n    Args:\n        dct_blocks (list): List of quantized DCT blocks.\n\n    Returns:\n        bitstring.BitArray: The extracted bits.\n    \"\"\"\n\n    extracted_data = \"\"\n    for current_dct_block in dct_blocks:\n        for i in range(1, len(current_dct_block)):\n            curr_coeff = np.int32(current_dct_block[i])\n            if (curr_coeff > 1):\n                extracted_bit = (np.uint8(curr_coeff) & 0x01) ^ 1\n                extracted_data += bitstring.pack('uint:1', extracted_bit) \n    return extracted_data\n\ndef stego_extract(file_path, key):\n    start_time1 = time.time()\n    print(\"\\nProcessing \", file_path)\n    try:\n        STEGO_IMAGE_FILEPATH  = file_path\n\n        gen_key = generate_key(key)\n\n        stego_image     = cv2.imread(STEGO_IMAGE_FILEPATH, flags=cv2.IMREAD_COLOR)\n        stego_image_f32 = np.float32(stego_image)\n        stego_image_YCC = YCC_Image(cv2.cvtColor(stego_image_f32, cv2.COLOR_BGR2YCrCb))\n\n        # FORWARD DCT STAGE\n        dct_blocks = [cv2.dct(block) for block in stego_image_YCC.channels[0]]  # Only care about Luminance layer\n\n        # QUANTIZATION STAGE\n        dct_quants = [np.around(np.divide(item, JPEG_STD_LUM_QUANT_TABLE)) for item in dct_blocks]\n\n        # Sort DCT coefficients by frequency\n        sorted_coefficients = [zigzag(block) for block in dct_quants]\n\n        # DATA EXTRACTION STAGE\n        recovered_data = _extract_bits_from_dct(sorted_coefficients)\n        #print(recovered_data)\n\n        # Check if enough bits are available to read the length of the secret message\n        if len(recovered_data) < 32:\n            raise ValueError(\"Not enough bits available to read the length of the secret message\")\n\n        recovered_data = bitstring.BitStream(recovered_data)\n        data_len = int(recovered_data.read('uint:32') / 8)\n        #print(data_len)\n\n        # Extract secret message from DCT coefficients\n        extracted_data = bytes()\n        for _ in range(data_len): \n            if len(recovered_data) < 8:\n                raise ValueError(\"Not enough bits available to read the secret message\")\n            extracted_data += struct.pack('>B', recovered_data.read('uint:8'))\n\n        #print(extracted_data)\n        decrypted_data = decrypt_message(extracted_data, gen_key)\n        recovered_message = decrypted_data.decode('ascii')\n\n        print(\"\\nRecovered message from \",stego_filename(file_path),\" : \", recovered_message)\n\n    except FileNotFoundError as e:\n        print(f\"Error: File not found - {e}\")\n    except cv2.error as e:\n        print(f\"Error: OpenCV error - {e}\")\n    except ValueError as e:\n        print(f\"Error: Data extraction failed - {e}\")\n    except Exception as e:  # Catch any other unexpected exceptions\n        print(f\"Error: An unexpected error occurred - {e}\")\n    \n    # Calculate the elapsed time\n    end_time1 = time.time()\n    elapsed_time1 = end_time1 - start_time1\n\n    # Print the result\n    print(f\"\\nTime taken: {elapsed_time1:.2f} seconds\\n\")\n\n\ndirectory = '/kaggle/working/'  # Directory of stego images\n\n# Get the list of file paths\nfile_paths = get_file_paths(directory)\n\nkey = input(\"Enter decryption key: \").encode()\n\n# Run Extraction\nfor file_path in file_paths:\n    stego_extract(file_path, key)\n    \nend_time = time.time()\n\n# Calculate the elapsed time\nelapsed_time = end_time - start_time\n\n# Print the result\nprint(f\"\\n\\nTotal time taken for execution: {elapsed_time:.2f} seconds\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **PSNR, MSE & SSIM**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom skimage.metrics import peak_signal_noise_ratio, mean_squared_error, structural_similarity\n\ndef calculate_metrics(original_image, reconstructed_image):\n    try:\n        original_img = cv2.imread(original_image)\n        reconstructed_img = cv2.imread(reconstructed_image)\n\n        if original_img is None:\n            raise FileNotFoundError(f\"Could not load original image: {original_image}\")\n        if reconstructed_img is None:\n            raise FileNotFoundError(f\"Could not load reconstructed image: {reconstructed_image}\")\n\n        # Convert to grayscale (SSIM is typically calculated on grayscale)\n        original_img_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n        reconstructed_img_gray = cv2.cvtColor(reconstructed_img, cv2.COLOR_BGR2GRAY)\n\n        # Ensure data types are suitable for the metrics\n        original_img = original_img.astype(np.float32)\n        reconstructed_img = reconstructed_img.astype(np.float32)\n        original_img_gray = original_img_gray.astype(np.float32)\n        reconstructed_img_gray = reconstructed_img_gray.astype(np.float32)\n\n        if original_img.shape != reconstructed_img.shape:\n            raise ValueError(\"Images must have the same dimensions.\")\n\n        mse = mean_squared_error(original_img, reconstructed_img)\n        psnr = peak_signal_noise_ratio(original_img, reconstructed_img, data_range=255)\n        ssim = structural_similarity(original_img_gray, reconstructed_img_gray, data_range=255, multichannel=False)\n\n        #return {\"psnr\": psnr, \"mse\": mse, \"ssim\": ssim}\n\n        print(f\"PSNR: {psnr:.2f} dB\")\n        print(f\"MSE: {mse:.4f}\")\n        print(f\"SSIM: {ssim:.4f}\")\n\n\n    except FileNotFoundError as e:\n        print(f\"Error: File not found - {e}\")\n    except cv2.error as e:\n        print(f\"Error: OpenCV error - {e}\")\n    except ValueError as e:\n        print(f\"Error: Data embedding failed - {e}\")\n    except Exception as e:  # Catch any other unexpected exceptions\n        print(f\"Error: An unexpected error occurred - {e}\")\n\n        \nstego_directory = \"/kaggle/working/\"\ncover_directory = \"/kaggle/input/test-dct/\"\n\nfile_paths = get_file_paths(stego_directory)\n\nfor file_path in file_paths:\n    original_image_path = cover_filename(file_path, cover_directory)\n    reconstructed_image_path = file_path\n    print(\"\\nProcessing\",original_image_path,\"with its stego\\n\")\n    calculate_metrics(original_image_path, reconstructed_image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Comparison Image Plotting**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_images_side_by_side(image1_path, image2_path):\n    # Load images\n    img1 = cv2.imread(image1_path)\n    img2 = cv2.imread(image2_path)\n    \n    # Ensure both images have the same dimensions\n    if img1.shape != img2.shape:\n        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n    \n    # Convert images from BGR to RGB\n    img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n    img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n    \n    # Convert images from BGR to YCbCr\n    img1_ycbcr = cv2.cvtColor(img1, cv2.COLOR_BGR2YCrCb)\n    img2_ycbcr = cv2.cvtColor(img2, cv2.COLOR_BGR2YCrCb)\n    \n    # Compute the difference image\n    diff_image = cv2.absdiff(img1, img2)\n    diff_image_rgb = cv2.cvtColor(diff_image, cv2.COLOR_BGR2RGB)\n    \n    # Highlight significant differences\n    _, diff_highlight = cv2.threshold(cv2.cvtColor(diff_image, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    diff_highlight_colored = cv2.cvtColor(diff_highlight, cv2.COLOR_GRAY2RGB)\n    \n    # Highlight bit manipulations\n    bit_diff = cv2.bitwise_xor(img1, img2)\n    bit_diff_highlight = cv2.cvtColor(bit_diff, cv2.COLOR_BGR2RGB)\n    \n    # Plot images side by side\n    fig, axes = plt.subplots(3, 2, figsize=(12, 24))\n    \n        # Original RGB Images\n    axes[0, 0].imshow(img1_rgb)\n    axes[0, 0].set_title('Cover - RGB')\n    axes[0, 0].axis('off')\n    \n    axes[0, 1].imshow(img2_rgb)\n    axes[0, 1].set_title('Stego - RGB')\n    axes[0, 1].axis('off')\n    \n    # YCbCr Images\n    axes[1, 0].imshow(img1_ycbcr)\n    axes[1, 0].set_title('Cover - YCbCr')\n    axes[1, 0].axis('off')\n    \n    axes[1, 1].imshow(img2_ycbcr)\n    axes[1, 1].set_title('Stego - YCbCr')\n    axes[1, 1].axis('off')\n    \n    # Highlighted Differences\n    axes[2, 0].imshow(diff_highlight_colored)\n    axes[2, 0].set_title('Highlighted Differences')\n    axes[2, 0].axis('off')\n    \n    # Bit Manipulation Highlight\n    axes[2, 1].imshow(bit_diff_highlight)\n    axes[2, 1].set_title('Bit Manipulation Highlight')\n    axes[2, 1].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\nstego_directory = \"/kaggle/working/\"\ncover_directory = \"/kaggle/input/test-dct/\"\n\nfile_paths = get_file_paths(stego_directory)\n\nfor file_path in file_paths:\n    image1_path = cover_filename(file_path, cover_directory)\n    image2_path = file_path\n    plot_images_side_by_side(image1_path, image2_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}